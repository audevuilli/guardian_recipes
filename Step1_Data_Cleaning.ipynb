{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Data Cleaning\n",
    "\n",
    "Open all the recipes data in one file and prepare them for further analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package ready\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library!\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer  \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize\n",
    "print('package ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the files in the folder!  \n",
    "files = glob.glob('guardian/*.csv')\n",
    "# read the files in a dataframe  \n",
    "data_df = [pd.read_csv(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all the files together  \n",
    "data = pd.concat(data_df,ignore_index=True)\n",
    "# Reset the index  \n",
    "data = data.reset_index()  \n",
    "# Drop the duplicates  \n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data (recipes) : (7603, 11)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>headline_list</th>\n",
       "      <th>category</th>\n",
       "      <th>author</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>article_content</th>\n",
       "      <th>comments_number</th>\n",
       "      <th>share_number</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-04-12T00:01:00+0100</td>\n",
       "      <td>My space</td>\n",
       "      <td>My space</td>\n",
       "      <td>Anna Chapman</td>\n",
       "      <td>The passionate entrepreneur Willy Harcourt-Coo...</td>\n",
       "      <td>E\\night years ago, my wife Tania and I came ba...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2009/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009-04-12T00:01:00+0100</td>\n",
       "      <td>Nigel Slater's Easter eggs</td>\n",
       "      <td>Nigel Slater recipes</td>\n",
       "      <td>Nigel Slater</td>\n",
       "      <td>Nothing comes with a trickier reputation to ma...</td>\n",
       "      <td>I\\nt is fair to say the eggs I am most interes...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>No Sharing</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2009/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0                      date               headline_list  \\\n",
       "0      0         0.0  2009-04-12T00:01:00+0100                    My space   \n",
       "1      1         1.0  2009-04-12T00:01:00+0100  Nigel Slater's Easter eggs   \n",
       "\n",
       "               category        author  \\\n",
       "0              My space  Anna Chapman   \n",
       "1  Nigel Slater recipes  Nigel Slater   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  The passionate entrepreneur Willy Harcourt-Coo...   \n",
       "1  Nothing comes with a trickier reputation to ma...   \n",
       "\n",
       "                                     article_content comments_number  \\\n",
       "0  E\\night years ago, my wife Tania and I came ba...     No Comments   \n",
       "1  I\\nt is fair to say the eggs I am most interes...     No Comments   \n",
       "\n",
       "  share_number                                                url  \n",
       "0            0  https://www.theguardian.com/lifeandstyle/2009/...  \n",
       "1   No Sharing  https://www.theguardian.com/lifeandstyle/2009/...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of data (recipes) : \" + str(data.shape))\n",
    "print()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column that we don't need\n",
    "data = data.drop(columns=['Unnamed: 0','index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                 0\n",
      "headline_list       28\n",
      "category            35\n",
      "author             349\n",
      "subtitle           210\n",
      "article_content      1\n",
      "comments_number      3\n",
      "share_number         3\n",
      "url                  2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look for null value in the data\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bit of cleaning\n",
    "\n",
    "# Delete all the article with category 'Family Life' - Not relevant for recipes analysis! \n",
    "data = data[data['category']!='Family life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check at the name of the author\n",
    "for i in data.author:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the author that have been wrongly webscraped!  \n",
    "data = data.replace({'[<meta content=\"Dale Berning Sawa\" name=\"author\"/>]':'Dale Berning Sawa',  \n",
    "                     '[<meta content=\"Chi-chi Nwanoku\" name=\"author\"/>]':'Chi-chi Nwanoku',  \n",
    "                     '[<meta content=\"Hugh Fearnley-Whittingstall\" name=\"author\"/>]':'Hugh Fearnley-Whittingstall',  \n",
    "                     '[<meta content=\"Jeanette Winterson\" name=\"author\"/>]':'Jeanette Winterson',  \n",
    "                     '[<meta content=\"Matthew Fort\" name=\"author\"/>]':'Matthew Fort',  \n",
    "                     '[<meta content=\"Susan McCarthy\" name=\"author\"/>]':'Susan McCarthy',  \n",
    "                     '[<meta content=\"Ariane Sherine\" name=\"author\"/>]':'Ariane Sherine',  \n",
    "                     '[<meta content=\"Ruby Tandoh\" name=\"author\"/>]':'Ruby Tandoh',  \n",
    "                     '[<meta content=\"the Guardian\" name=\"author\"/>]':'the Guardian',  \n",
    "                     '[<meta content=\"Romy Ash\" name=\"author\"/>, <meta content=\"Sarah Trotter\" name=\"author\"/>, <meta content=\"Romy Ash\" name=\"author\"/>, <meta content=\"Lauren Bamford\" name=\"author\"/>, <meta content=\"Sarah Trotter\" name=\"author\"/>]':'Romy Ash, Sara Trotter, Lauren Bamford',  \n",
    "                     '[<meta content=\"Clem Bastow\" name=\"author\"/>]':'Clem Bastow',  \n",
    "                     '[<meta content=\"Yotam Ottolenghi\" name=\"author\"/>, <meta content=\"Uyen Luu\" name=\"author\"/>, <meta content=\"David Frenkiel\" name=\"author\"/>, <meta content=\"Luise Vindahl\" name=\"author\"/>, <meta content=\"Caroline Craig\" name=\"author\"/>]':'Caroline Craig, Luise Vindahl, Yotam Ottolenghi, Uyen Luu, David Frenkiel',  \n",
    "                     'Yotam Ottlenghi':'Yotam Ottolenghi','Yuki Sugiura, Valerie Berry, Lee Gould, Rachel Vere and Music by Evan Gildersleeve, theguardian.com':'Yuki Sugiura, Valerie Berry, Lee Gould, Rachel Vere',\n",
    "                     'Hugh-Fearnley Whittingstall':'Hugh Fearnley-Whittingstall','Hugh Fearnley-Whittinstall':'Hugh Fearnley-Whittingstall'})\n",
    "\n",
    "# If NaN for authors and NaN for subtitle -> change it to none!   \n",
    "values = {'author': 'none', 'subtitle':'none'}  \n",
    "data = data.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audevuilliomenet/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Check for the no comments and no url!\n",
    "test = data[data['comments_number'].isnull()]  \n",
    "test.share_number = 'No Sharing'  \n",
    "data.append(test)\n",
    "\n",
    "change = data[(data['date'] == '2015-01-20') & (data['author']== 'Ruby Tandoh' )]  \n",
    "change.share_number = 52  \n",
    "change.url = 'https://www.theguardian.com/lifeandstyle/2015/jan/20/best-baking-recipes-from-2014-ruby-tandoh'  \n",
    "change.comments_number = 25  \n",
    "data.append(change)\n",
    "\n",
    "print(\"Change ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows (recipes), data clean: (7504, 9)\n",
      "\n",
      "Data Clean\n"
     ]
    }
   ],
   "source": [
    "# Remove the rows if NaN is in url, headline_list, share_number and category after having make the above change!  \n",
    "data = data.dropna(subset = ['headline_list','url','share_number','category'])  \n",
    "\n",
    "print('Number of rows (recipes), data clean: ' + str(data.shape))\n",
    "print(\"\")\n",
    "print('Data Clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               object\n",
       "headline_list      object\n",
       "category           object\n",
       "author             object\n",
       "subtitle           object\n",
       "article_content    object\n",
       "comments_number    object\n",
       "share_number       object\n",
       "url                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the types of the data!\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the data date to date instead of object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separe the date in year and month\n",
    "# Remove the strings of time in date. Keep only the day and the month.b  \n",
    "data.date = data.date.str.replace('T\\d.*','')  \n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Add a column in dataframe for the year, month and day  \n",
    "data['year'] = data['date'].dt.year  \n",
    "data['month'] = data['date'].dt.month_name()  \n",
    "data['day'] = data['date'].dt.day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline_list\n",
      "step 1: punctuation remove\n",
      "step 2: words in lowercase\n",
      "step 3: nonstopwords and special characters removed\n",
      "step 4: words tokenize\n",
      "Data Clean Finish\n",
      "\n",
      "subtitle\n",
      "step 1: punctuation remove\n",
      "step 2: words in lowercase\n",
      "step 3: nonstopwords and special characters removed\n",
      "step 4: words tokenize\n",
      "Data Clean Finish\n",
      "\n",
      "article_content\n",
      "step 1: punctuation remove\n",
      "step 2: words in lowercase\n",
      "step 3: nonstopwords and special characters removed\n",
      "step 4: words tokenize\n",
      "Data Clean Finish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Function for tokenization and cleaning text!   \n",
    "cleaning = ['headline_list','subtitle','article_content']  \n",
    "stop = stopwords.words('english')  \n",
    "\n",
    "def cleandata(data):\n",
    "        for i in cleaning:\n",
    "                print(str(i))\n",
    "                # Remove the punctuation  \n",
    "                data['clean_'+str(i)] = data[i].apply(lambda x:x.translate(str.maketrans('','', string.punctuation)))  \n",
    "                print('step 1: punctuation remove')\n",
    "\n",
    "                # Remove the '\\\\n' line_brakes  \n",
    "                data['clean_'+str(i)] = data['clean_'+str(i)].str.replace(r'\\n',' ')\n",
    "                # Get all the words in lowercase  \n",
    "                data['clean_'+str(i)] = data['clean_'+str(i)].str.lower()  \n",
    "                if i == 'article_content':\n",
    "                    data['clean_'+str(i)] = data['clean_'+str(i)].str.replace(r'Since you’re here.*','')\n",
    "                print('step 2: words in lowercase')\n",
    "\n",
    "                # Remove all the english stopwords!  \n",
    "                data['nostop_words_'+'clean_'+str(i)] = data['clean_'+str(i)].apply(  \n",
    "                lambda x: ' '.join([word for word in x.split() if word not in (stop)]))  \n",
    "                # Remove the special characters!  \n",
    "                data['nostop_words_'+'clean_'+str(i)] = data['nostop_words_'+'clean_'+str(i)].str.replace(r\"\\’|\\s\\–|\\'\",'')                                                                                    \n",
    "                data['nostop_words_'+'clean_'+str(i)] = data['nostop_words_'+'clean_'+str(i)].str.replace(r'[0-9]+', '')\n",
    "                \n",
    "                print('step 3: nonstopwords and special characters removed')\n",
    "\n",
    "                # Tokenize the text  \n",
    "                data['token_'+str(i)] = data['nostop_words_'+'clean_'+str(i)].apply(word_tokenize)\n",
    "                print('step 4: words tokenize')\n",
    "                print('Data Clean Finish')\n",
    "                print(\"\")\n",
    "                \n",
    "              #data['clean_'+str(i)] = data['clean_'+str(i)].str.replace(guardian1,'')\n",
    "                \n",
    "        return\n",
    "\n",
    "cleandata(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline_list</th>\n",
       "      <th>category</th>\n",
       "      <th>author</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>article_content</th>\n",
       "      <th>comments_number</th>\n",
       "      <th>share_number</th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>day</th>\n",
       "      <th>clean_headline_list</th>\n",
       "      <th>nostop_words_clean_headline_list</th>\n",
       "      <th>token_headline_list</th>\n",
       "      <th>clean_subtitle</th>\n",
       "      <th>nostop_words_clean_subtitle</th>\n",
       "      <th>token_subtitle</th>\n",
       "      <th>clean_article_content</th>\n",
       "      <th>nostop_words_clean_article_content</th>\n",
       "      <th>token_article_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-04-12</td>\n",
       "      <td>My space</td>\n",
       "      <td>My space</td>\n",
       "      <td>Anna Chapman</td>\n",
       "      <td>The passionate entrepreneur Willy Harcourt-Coo...</td>\n",
       "      <td>E\\night years ago, my wife Tania and I came ba...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2009/...</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>my space</td>\n",
       "      <td>space</td>\n",
       "      <td>[space]</td>\n",
       "      <td>the passionate entrepreneur willy harcourtcooz...</td>\n",
       "      <td>passionate entrepreneur willy harcourtcooze op...</td>\n",
       "      <td>[passionate, entrepreneur, willy, harcourtcooz...</td>\n",
       "      <td>e ight years ago my wife tania and i came back...</td>\n",
       "      <td>e ight years ago wife tania came back venezuel...</td>\n",
       "      <td>[e, ight, years, ago, wife, tania, came, back,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-04-12</td>\n",
       "      <td>Nigel Slater's Easter eggs</td>\n",
       "      <td>Nigel Slater recipes</td>\n",
       "      <td>Nigel Slater</td>\n",
       "      <td>Nothing comes with a trickier reputation to ma...</td>\n",
       "      <td>I\\nt is fair to say the eggs I am most interes...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>No Sharing</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2009/...</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>nigel slaters easter eggs</td>\n",
       "      <td>nigel slaters easter eggs</td>\n",
       "      <td>[nigel, slaters, easter, eggs]</td>\n",
       "      <td>nothing comes with a trickier reputation to ma...</td>\n",
       "      <td>nothing comes trickier reputation make soufflé...</td>\n",
       "      <td>[nothing, comes, trickier, reputation, make, s...</td>\n",
       "      <td>i t is fair to say the eggs i am most interest...</td>\n",
       "      <td>fair say eggs interested come weekend wrapped ...</td>\n",
       "      <td>[fair, say, eggs, interested, come, weekend, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date               headline_list              category        author  \\\n",
       "0 2009-04-12                    My space              My space  Anna Chapman   \n",
       "1 2009-04-12  Nigel Slater's Easter eggs  Nigel Slater recipes  Nigel Slater   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  The passionate entrepreneur Willy Harcourt-Coo...   \n",
       "1  Nothing comes with a trickier reputation to ma...   \n",
       "\n",
       "                                     article_content comments_number  \\\n",
       "0  E\\night years ago, my wife Tania and I came ba...     No Comments   \n",
       "1  I\\nt is fair to say the eggs I am most interes...     No Comments   \n",
       "\n",
       "  share_number                                                url  year  ...  \\\n",
       "0            0  https://www.theguardian.com/lifeandstyle/2009/...  2009  ...   \n",
       "1   No Sharing  https://www.theguardian.com/lifeandstyle/2009/...  2009  ...   \n",
       "\n",
       "  day        clean_headline_list nostop_words_clean_headline_list  \\\n",
       "0  12                   my space                            space   \n",
       "1  12  nigel slaters easter eggs        nigel slaters easter eggs   \n",
       "\n",
       "              token_headline_list  \\\n",
       "0                         [space]   \n",
       "1  [nigel, slaters, easter, eggs]   \n",
       "\n",
       "                                      clean_subtitle  \\\n",
       "0  the passionate entrepreneur willy harcourtcooz...   \n",
       "1  nothing comes with a trickier reputation to ma...   \n",
       "\n",
       "                         nostop_words_clean_subtitle  \\\n",
       "0  passionate entrepreneur willy harcourtcooze op...   \n",
       "1  nothing comes trickier reputation make soufflé...   \n",
       "\n",
       "                                      token_subtitle  \\\n",
       "0  [passionate, entrepreneur, willy, harcourtcooz...   \n",
       "1  [nothing, comes, trickier, reputation, make, s...   \n",
       "\n",
       "                               clean_article_content  \\\n",
       "0  e ight years ago my wife tania and i came back...   \n",
       "1  i t is fair to say the eggs i am most interest...   \n",
       "\n",
       "                  nostop_words_clean_article_content  \\\n",
       "0  e ight years ago wife tania came back venezuel...   \n",
       "1  fair say eggs interested come weekend wrapped ...   \n",
       "\n",
       "                               token_article_content  \n",
       "0  [e, ight, years, ago, wife, tania, came, back,...  \n",
       "1  [fair, say, eggs, interested, come, weekend, w...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data clean and save in csv file\n"
     ]
    }
   ],
   "source": [
    "# Save the Clean Text in a CSV file\n",
    "data.to_csv('guardian_clean_data.csv')\n",
    "print('data clean and save in csv file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

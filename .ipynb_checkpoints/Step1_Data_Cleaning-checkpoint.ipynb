{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Data Cleaning\n",
    "\n",
    "Open all the recipes data in one file and prepare them for further analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package ready\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library!\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer  \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize\n",
    "print('package ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the files in the folder!  \n",
    "files = glob.glob('guardian/*.csv')\n",
    "# read the files in a dataframe  \n",
    "data_df = [pd.read_csv(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4ca539d18f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Append all the files together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Sort by date and Reset the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Drop the duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Append all the files together  \n",
    "data = pd.concat(data_df,ignore_index=True)\n",
    "# Sort by date and Reset the index  \n",
    "data = data.sort_values(['date']).reset_index()  \n",
    "# Drop the duplicates  \n",
    "data = data.drop_duplicates(['date','headline_list','author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data (recipes) : (7439, 9)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline_list</th>\n",
       "      <th>category</th>\n",
       "      <th>author</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>article_content</th>\n",
       "      <th>comments_number</th>\n",
       "      <th>share_number</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-10-18T00:01:00+0100</td>\n",
       "      <td>Good fast food</td>\n",
       "      <td>Cooking for kids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's that familiar scene: hardly any food in t...</td>\n",
       "      <td>Stringy stretchy omelettes\\nEggs are obviously...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2008/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-10-18T00:01:00+0100</td>\n",
       "      <td>Top 10</td>\n",
       "      <td>Cooking for kids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sandwich fillings</td>\n",
       "      <td>1 Cheese and tomato\\n2 Apple slaw: mix mayonna...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2008/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date   headline_list          category author  \\\n",
       "0  2008-10-18T00:01:00+0100  Good fast food  Cooking for kids    NaN   \n",
       "1  2008-10-18T00:01:00+0100          Top 10  Cooking for kids    NaN   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  It's that familiar scene: hardly any food in t...   \n",
       "1                                  Sandwich fillings   \n",
       "\n",
       "                                     article_content comments_number  \\\n",
       "0  Stringy stretchy omelettes\\nEggs are obviously...     No Comments   \n",
       "1  1 Cheese and tomato\\n2 Apple slaw: mix mayonna...     No Comments   \n",
       "\n",
       "  share_number                                                url  \n",
       "0            0  https://www.theguardian.com/lifeandstyle/2008/...  \n",
       "1            0  https://www.theguardian.com/lifeandstyle/2008/...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of data (recipes) : \" + str(data.shape))\n",
    "print()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column that we don't need\n",
    "data = data.drop(columns=['Unnamed: 0','index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                 0\n",
      "headline_list        3\n",
      "category            10\n",
      "author             320\n",
      "subtitle           185\n",
      "article_content      1\n",
      "comments_number      3\n",
      "share_number         3\n",
      "url                  2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look for null value in the data\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bit of cleaning\n",
    "# Delete all the article with category 'Family Life' - Not relevant for recipes analysis! \n",
    "data = data[data['category']!='Family life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check at the name of the author\n",
    "#for i in data.author:\n",
    "  #  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the author that have been wrongly webscraped!  \n",
    "data = data.replace({'[<meta content=\"Dale Berning Sawa\" name=\"author\"/>]':'Dale Berning Sawa',  \n",
    "                     '[<meta content=\"Chi-chi Nwanoku\" name=\"author\"/>]':'Chi-chi Nwanoku',  \n",
    "                     '[<meta content=\"Hugh Fearnley-Whittingstall\" name=\"author\"/>]':'Hugh Fearnley-Whittingstall',  \n",
    "                     '[<meta content=\"Jeanette Winterson\" name=\"author\"/>]':'Jeanette Winterson',  \n",
    "                     '[<meta content=\"Matthew Fort\" name=\"author\"/>]':'Matthew Fort',  \n",
    "                     '[<meta content=\"Susan McCarthy\" name=\"author\"/>]':'Susan McCarthy',  \n",
    "                     '[<meta content=\"Ariane Sherine\" name=\"author\"/>]':'Ariane Sherine',  \n",
    "                     '[<meta content=\"Ruby Tandoh\" name=\"author\"/>]':'Ruby Tandoh',  \n",
    "                     '[<meta content=\"the Guardian\" name=\"author\"/>]':'the Guardian',  \n",
    "                     '[<meta content=\"Romy Ash\" name=\"author\"/>, <meta content=\"Sarah Trotter\" name=\"author\"/>, <meta content=\"Romy Ash\" name=\"author\"/>, <meta content=\"Lauren Bamford\" name=\"author\"/>, <meta content=\"Sarah Trotter\" name=\"author\"/>]':'Romy Ash, Sara Trotter, Lauren Bamford',  \n",
    "                     '[<meta content=\"Clem Bastow\" name=\"author\"/>]':'Clem Bastow',  \n",
    "                     '[<meta content=\"Yotam Ottolenghi\" name=\"author\"/>, <meta content=\"Uyen Luu\" name=\"author\"/>, <meta content=\"David Frenkiel\" name=\"author\"/>, <meta content=\"Luise Vindahl\" name=\"author\"/>, <meta content=\"Caroline Craig\" name=\"author\"/>]':'Caroline Craig, Luise Vindahl, Yotam Ottolenghi, Uyen Luu, David Frenkiel',  \n",
    "                     'Yotam Ottlenghi':'Yotam Ottolenghi','Yuki Sugiura, Valerie Berry, Lee Gould, Rachel Vere and Music by Evan Gildersleeve, theguardian.com':'Yuki Sugiura, Valerie Berry, Lee Gould, Rachel Vere',\n",
    "                     'Hugh-Fearnley Whittingstall':'Hugh Fearnley-Whittingstall','Hugh Fearnley-Whittinstall':'Hugh Fearnley-Whittingstall'})\n",
    "\n",
    "# If NaN for authors and NaN for subtitle -> change it to none!   \n",
    "values = {'author': 'none', 'subtitle':'none'}  \n",
    "data = data.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audevuilliomenet/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Check for the no comments and no url!\n",
    "test = data[data['comments_number'].isnull()]  \n",
    "test.share_number = 'No Sharing'  \n",
    "data.append(test)\n",
    "\n",
    "change = data[(data['date'] == '2015-01-20') & (data['author']== 'Ruby Tandoh' )]  \n",
    "change.share_number = 52  \n",
    "change.url = 'https://www.theguardian.com/lifeandstyle/2015/jan/20/best-baking-recipes-from-2014-ruby-tandoh'  \n",
    "change.comments_number = 25  \n",
    "data.append(change)\n",
    "\n",
    "print(\"Change ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows (recipes), data clean: (7365, 9)\n",
      "\n",
      "Data Clean\n"
     ]
    }
   ],
   "source": [
    "# Remove the rows if NaN is in url, headline_list, share_number and category after having make the above change!  \n",
    "data = data.dropna(subset = ['headline_list','url','share_number','category'])  \n",
    "\n",
    "print('Number of rows (recipes), data clean: ' + str(data.shape))\n",
    "print(\"\")\n",
    "print('Data Clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the types of the data!\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline_list</th>\n",
       "      <th>category</th>\n",
       "      <th>author</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>article_content</th>\n",
       "      <th>comments_number</th>\n",
       "      <th>share_number</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-10-18T00:01:00+0100</td>\n",
       "      <td>Good fast food</td>\n",
       "      <td>Cooking for kids</td>\n",
       "      <td>none</td>\n",
       "      <td>It's that familiar scene: hardly any food in t...</td>\n",
       "      <td>Stringy stretchy omelettes\\nEggs are obviously...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2008/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-10-18T00:01:00+0100</td>\n",
       "      <td>Top 10</td>\n",
       "      <td>Cooking for kids</td>\n",
       "      <td>none</td>\n",
       "      <td>Sandwich fillings</td>\n",
       "      <td>1 Cheese and tomato\\n2 Apple slaw: mix mayonna...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2008/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date   headline_list          category author  \\\n",
       "0  2008-10-18T00:01:00+0100  Good fast food  Cooking for kids   none   \n",
       "1  2008-10-18T00:01:00+0100          Top 10  Cooking for kids   none   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  It's that familiar scene: hardly any food in t...   \n",
       "1                                  Sandwich fillings   \n",
       "\n",
       "                                     article_content comments_number  \\\n",
       "0  Stringy stretchy omelettes\\nEggs are obviously...     No Comments   \n",
       "1  1 Cheese and tomato\\n2 Apple slaw: mix mayonna...     No Comments   \n",
       "\n",
       "  share_number                                                url  \n",
       "0            0  https://www.theguardian.com/lifeandstyle/2008/...  \n",
       "1            0  https://www.theguardian.com/lifeandstyle/2008/...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the data date to date instead of object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separe the date in year and month\n",
    "# Remove the strings of time in date. Keep only the day and the month.b  \n",
    "data.date = data.date.str.replace('T\\d.*','')  \n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Add a column in dataframe for the year, month and day  \n",
    "data['year'] = data['date'].dt.year  \n",
    "data['month'] = data['date'].dt.month_name()  \n",
    "data['day'] = data['date'].dt.day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline_list\n",
      "step 1: punctuation remove\n",
      "step 2: words in lowercase\n",
      "step 3: nonstopwords and special characters removed\n",
      "step 4: words tokenize\n",
      "Data Clean Finish\n",
      "\n",
      "subtitle\n",
      "step 1: punctuation remove\n",
      "step 2: words in lowercase\n",
      "step 3: nonstopwords and special characters removed\n",
      "step 4: words tokenize\n",
      "Data Clean Finish\n",
      "\n",
      "article_content\n",
      "step 1: punctuation remove\n",
      "step 2: words in lowercase\n",
      "step 3: nonstopwords and special characters removed\n",
      "step 4: words tokenize\n",
      "Data Clean Finish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Function for tokenization and cleaning text!   \n",
    "cleaning = ['headline_list','subtitle','article_content']  \n",
    "stop = stopwords.words('english')  \n",
    "\n",
    "def cleandata(data):\n",
    "        for i in cleaning:\n",
    "                print(str(i))\n",
    "                # Remove the punctuation  \n",
    "                data['clean_'+str(i)] = data[i].apply(lambda x:x.translate(str.maketrans('','', string.punctuation)))  \n",
    "                print('step 1: punctuation remove')\n",
    "\n",
    "                # Remove the '\\\\n' line_brakes  \n",
    "                data['clean_'+str(i)] = data['clean_'+str(i)].str.replace(r'\\n',' ')\n",
    "                # Get all the words in lowercase  \n",
    "                data['clean_'+str(i)] = data['clean_'+str(i)].str.lower()  \n",
    "                if i == 'article_content':\n",
    "                    data['clean_'+str(i)] = data['clean_'+str(i)].str.replace(r'since you’re here.*','')\n",
    "                print('step 2: words in lowercase')\n",
    "\n",
    "                # Remove all the english stopwords!  \n",
    "                data['nostop_words_'+'clean_'+str(i)] = data['clean_'+str(i)].apply(  \n",
    "                lambda x: ' '.join([word for word in x.split() if word not in (stop)]))  \n",
    "                # Remove the special characters!  \n",
    "                data['nostop_words_'+'clean_'+str(i)] = data['nostop_words_'+'clean_'+str(i)].str.replace(r\"\\’|\\s\\–|\\'\",'')                                                                                    \n",
    "                data['nostop_words_'+'clean_'+str(i)] = data['nostop_words_'+'clean_'+str(i)].str.replace(r'[0-9]+', '')\n",
    "                \n",
    "                print('step 3: nonstopwords and special characters removed')\n",
    "\n",
    "                # Tokenize the text  \n",
    "                data['token_'+str(i)] = data['nostop_words_'+'clean_'+str(i)].apply(word_tokenize)\n",
    "                print('step 4: words tokenize')\n",
    "                print('Data Clean Finish')\n",
    "                print(\"\")\n",
    "                \n",
    "              #data['clean_'+str(i)] = data['clean_'+str(i)].str.replace(guardian1,'')\n",
    "                \n",
    "        return\n",
    "\n",
    "cleandata(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline_list</th>\n",
       "      <th>category</th>\n",
       "      <th>author</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>article_content</th>\n",
       "      <th>comments_number</th>\n",
       "      <th>share_number</th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>day</th>\n",
       "      <th>clean_headline_list</th>\n",
       "      <th>nostop_words_clean_headline_list</th>\n",
       "      <th>token_headline_list</th>\n",
       "      <th>clean_subtitle</th>\n",
       "      <th>nostop_words_clean_subtitle</th>\n",
       "      <th>token_subtitle</th>\n",
       "      <th>clean_article_content</th>\n",
       "      <th>nostop_words_clean_article_content</th>\n",
       "      <th>token_article_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-10-18</td>\n",
       "      <td>Good fast food</td>\n",
       "      <td>Cooking for kids</td>\n",
       "      <td>none</td>\n",
       "      <td>It's that familiar scene: hardly any food in t...</td>\n",
       "      <td>Stringy stretchy omelettes\\nEggs are obviously...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2008/...</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>good fast food</td>\n",
       "      <td>good fast food</td>\n",
       "      <td>[good, fast, food]</td>\n",
       "      <td>its that familiar scene hardly any food in the...</td>\n",
       "      <td>familiar scene hardly food house gaggle hungry...</td>\n",
       "      <td>[familiar, scene, hardly, food, house, gaggle,...</td>\n",
       "      <td>stringy stretchy omelettes eggs are obviously ...</td>\n",
       "      <td>stringy stretchy omelettes eggs obviously sent...</td>\n",
       "      <td>[stringy, stretchy, omelettes, eggs, obviously...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-10-18</td>\n",
       "      <td>Top 10</td>\n",
       "      <td>Cooking for kids</td>\n",
       "      <td>none</td>\n",
       "      <td>Sandwich fillings</td>\n",
       "      <td>1 Cheese and tomato\\n2 Apple slaw: mix mayonna...</td>\n",
       "      <td>No Comments</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.theguardian.com/lifeandstyle/2008/...</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>top 10</td>\n",
       "      <td>top</td>\n",
       "      <td>[top]</td>\n",
       "      <td>sandwich fillings</td>\n",
       "      <td>sandwich fillings</td>\n",
       "      <td>[sandwich, fillings]</td>\n",
       "      <td>1 cheese and tomato 2 apple slaw mix mayonnais...</td>\n",
       "      <td>cheese tomato  apple slaw mix mayonnaise lemo...</td>\n",
       "      <td>[cheese, tomato, apple, slaw, mix, mayonnaise,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   headline_list          category author  \\\n",
       "0 2008-10-18  Good fast food  Cooking for kids   none   \n",
       "1 2008-10-18          Top 10  Cooking for kids   none   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  It's that familiar scene: hardly any food in t...   \n",
       "1                                  Sandwich fillings   \n",
       "\n",
       "                                     article_content comments_number  \\\n",
       "0  Stringy stretchy omelettes\\nEggs are obviously...     No Comments   \n",
       "1  1 Cheese and tomato\\n2 Apple slaw: mix mayonna...     No Comments   \n",
       "\n",
       "  share_number                                                url  year  ...  \\\n",
       "0            0  https://www.theguardian.com/lifeandstyle/2008/...  2008  ...   \n",
       "1            0  https://www.theguardian.com/lifeandstyle/2008/...  2008  ...   \n",
       "\n",
       "  day  clean_headline_list nostop_words_clean_headline_list  \\\n",
       "0  18       good fast food                   good fast food   \n",
       "1  18               top 10                             top    \n",
       "\n",
       "  token_headline_list                                     clean_subtitle  \\\n",
       "0  [good, fast, food]  its that familiar scene hardly any food in the...   \n",
       "1               [top]                                  sandwich fillings   \n",
       "\n",
       "                         nostop_words_clean_subtitle  \\\n",
       "0  familiar scene hardly food house gaggle hungry...   \n",
       "1                                  sandwich fillings   \n",
       "\n",
       "                                      token_subtitle  \\\n",
       "0  [familiar, scene, hardly, food, house, gaggle,...   \n",
       "1                               [sandwich, fillings]   \n",
       "\n",
       "                               clean_article_content  \\\n",
       "0  stringy stretchy omelettes eggs are obviously ...   \n",
       "1  1 cheese and tomato 2 apple slaw mix mayonnais...   \n",
       "\n",
       "                  nostop_words_clean_article_content  \\\n",
       "0  stringy stretchy omelettes eggs obviously sent...   \n",
       "1   cheese tomato  apple slaw mix mayonnaise lemo...   \n",
       "\n",
       "                               token_article_content  \n",
       "0  [stringy, stretchy, omelettes, eggs, obviously...  \n",
       "1  [cheese, tomato, apple, slaw, mix, mayonnaise,...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data clean and save in csv file\n"
     ]
    }
   ],
   "source": [
    "# Save the Clean Text in a CSV file\n",
    "data = data.drop_duplicates(['date','headline_list'],keep='first')\n",
    "data.to_csv('guardian_clean_data.csv')\n",
    "print('data clean and save in csv file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
